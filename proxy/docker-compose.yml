services:
  proxy:
    image: 'docker.io/jc21/nginx-proxy-manager:2.12.3'
    container_name: proxy
    restart: unless-stopped
    ports:
      - '80:80'
      - '81:81'
      - '443:443'
    volumes:
      - ./services/proxy/data:/data
      - ./services/proxy/letsencrypt:/etc/letsencrypt
    networks:
      - proxy-net

  ollama:
    image: ollama/ollama:0.6.8
    container_name: ollama
    restart: unless-stopped
    volumes:
      - ./services/ollama:/root/.ollama
      - ./zscaler_cert:/tmp/zscaler_cert
    ports:
      - "${OLLAMA_EXPSPORT}:${OLLAMA_EXPSPORT}"
    environment:
      VIRTUAL_HOST:  ${OLLAMA_HOSTNAME}
      WEB_PORTS: "${OLLAMA_HOSTPORT}"
    networks:
      - proxy-net

  chroma:
    image: chromadb/chroma:1.0.8
    container_name: chroma
    restart: unless-stopped
    volumes:
      - ./services/chroma:/chroma/chroma
    ports:
      - "${CHROMA_EXPSPORT}:${CHROMA_EXPSPORT}"
    environment:
      VIRTUAL_HOST:  ${CHROMA_HOSTNAME}
      WEB_PORTS: ${CHROMA_HOSTPORT}
    networks:
      - proxy-net

  openweb:
    image: ghcr.io/open-webui/open-webui:git-de0f52b-ollama
    container_name: openweb
    restart: unless-stopped
    volumes:
      - ./services/openweb:/openweb-ui
    ports:
      - "${OPENUI_EXPSPORT}:${OPENUI_EXPSPORT}"
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434/api
      - VIRTUAL_HOST=${OPENUI_HOSTNAME}
      - VIRTUAL_PORT=${OPENUI_HOSTPORT}
    depends_on:
      - ollama
    networks:
      - proxy-net

networks:
  proxy-net:
